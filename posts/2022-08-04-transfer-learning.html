<article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Transfer learning in Deep learning</h1><p class="page-description">blog.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="" itemprop="datePublished">
        
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      1 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/personal_page/categories/#markdown">markdown</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h1"><a href="#transfer-learning-in-deep-learning">Transfer learning in Deep learning</a>
<ul>
<li class="toc-entry toc-h2"><a href="#the-visual-task-adaptation-benchmark">The Visual Task Adaptation Benchmark</a></li>
<li class="toc-entry toc-h2"><a href="#pretained-models">Pretained models</a></li>
<li class="toc-entry toc-h2"><a href="#footnotes">Footnotes</a></li>
</ul>
</li>
</ul><h1 id="transfer-learning-in-deep-learning">
<a class="anchor" href="#transfer-learning-in-deep-learning" aria-hidden="true"><span class="octicon octicon-link"></span></a>Transfer learning in Deep learning</h1>

<p>由于loss的非凸性、type的不同，造成Transfer learning在不同的数据、task上表现并没有规律性。</p>

<p><img src="./images/VTAB_loss.png" alt="" title="VTAB protocol"></p>

<h2 id="the-visual-task-adaptation-benchmark">
<a class="anchor" href="#the-visual-task-adaptation-benchmark" aria-hidden="true"><span class="octicon octicon-link"></span></a>The Visual Task Adaptation Benchmark</h2>

<p><a href="https://ai.googleblog.com/2019/11/the-visual-task-adaptation-benchmark.html">VTAB</a>基于多种数据、多种任务之间的Transfer learning。</p>

<p>当数据量增加的时候，从scratch训练，不会有performance的损失。</p>

<p><img src="./images/VTAB_scratch.png" alt="" title="Performance"></p>

<h2 id="pretained-models">
<a class="anchor" href="#pretained-models" aria-hidden="true"><span class="octicon octicon-link"></span></a>Pretained models</h2>

<p>不能想当然的认为pretained models是有用的，参考<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup>，主要的问题有：</p>

<ol>
  <li>
    <p>不同的task</p>
  </li>
  <li>
    <p>数据有很大的difference，如果不能share feature，那么不会有什么好处</p>
  </li>
  <li>
    <p>pretained models是local optima，所以会有bias</p>
  </li>
</ol>

<p>当然，也可以用pretained models做初始值，最后的结果基本也会差不多<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup>。也有文章证明即使是training from scratch<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote" rel="footnote">3</a></sup>，结果也不会差很多<sup id="fnref:4" role="doc-noteref"><a href="#fn:4" class="footnote" rel="footnote">4</a></sup>。</p>

<h2 id="footnotes">
<a class="anchor" href="#footnotes" aria-hidden="true"><span class="octicon octicon-link"></span></a>Footnotes</h2>
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>https://news.ycombinator.com/item?id=33067056. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">↩</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>https://stackoverflow.com/questions/65982245/pretrained-model-or-training-from-scratch-for-object-detection. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">↩</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>https://arxiv.org/abs/1811.08883. <a href="#fnref:3" class="reversefootnote" role="doc-backlink">↩</a></p>
    </li>
    <li id="fn:4" role="doc-endnote">
      <p>https://heartbeat.comet.ml/pre-trained-machine-learning-models-vs-models-trained-from-scratch-63e079ed648f. <a href="#fnref:4" class="reversefootnote" role="doc-backlink">↩</a></p>
    </li>
  </ol>
</div>

  </div><a class="u-url" href="/personal_page/posts/2022-08-04-transfer-learning.html" hidden></a>
</article>
