<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://whuwuteng.github.io/personal_page/feed.xml" rel="self" type="application/atom+xml" /><link href="https://whuwuteng.github.io/personal_page/" rel="alternate" type="text/html" /><updated>2024-04-21T05:23:01-05:00</updated><id>https://whuwuteng.github.io/personal_page/feed.xml</id><title type="html">whuwuteng(吴腾)</title><subtitle>Research Blog</subtitle><entry><title type="html">LiDAR测量原理</title><link href="https://whuwuteng.github.io/personal_page/markdown/2024/04/15/LiDAR.html" rel="alternate" type="text/html" title="LiDAR测量原理" /><published>2024-04-15T00:00:00-05:00</published><updated>2024-04-15T00:00:00-05:00</updated><id>https://whuwuteng.github.io/personal_page/markdown/2024/04/15/LiDAR</id><content type="html" xml:base="https://whuwuteng.github.io/personal_page/markdown/2024/04/15/LiDAR.html">&lt;h1 id=&quot;lidar测量原理&quot;&gt;LiDAR测量原理&lt;/h1&gt;

&lt;h2 id=&quot;引言&quot;&gt;引言&lt;/h2&gt;

&lt;p&gt;在摄影测量中，有很多文档对于相机的原理的进行分析，但是对于LiDAR的测量原理分析的并不多。可能的原因是，在实际测量的过程中，对于LiDAR的测量数据，处理时都已经是点云了，因此不太关注它的原理。&lt;/p&gt;

&lt;p&gt;同时，有一点值得说明的是，在技术原理上LiDAR与RADAR上有许多相似的地方，这是值得思考的地方。&lt;/p&gt;

&lt;p&gt;不过对于多源数据处理，或想通过在几何上处理的(例如ray tracing)，了解原理还是很重要的。&lt;/p&gt;

&lt;p&gt;《Airborne and Terrestrial Laser Scanning》by George Vosselman, Hans-Gerd Maas 的第一章就是介绍原理的。&lt;/p&gt;

&lt;p&gt;LiDAR很早之前就用于水下测量(bathymetry)，主要是(蓝)绿色波段(532 nm)，具有更强的能量。&lt;/p&gt;

&lt;p&gt;https://www.britannica.com/science/color/The-visible-spectrum&lt;/p&gt;

&lt;p&gt;下面的内容主要围绕近红外(～1064 nm)LiDAR进行展开讨论。&lt;/p&gt;

&lt;p&gt;从原理上讲，主要有两种方式：Time-of-flight 与Phase based method ：&lt;/p&gt;

&lt;p&gt;https://www.laserscanning-europe.com/en/servicesdevices/terrestrial-laser-scanners&lt;/p&gt;

&lt;p&gt;Forward-looking infrared(FLIR) 是一种被动的红外摄影相机，目前应用遥感与车载等。&lt;/p&gt;

&lt;p&gt;从1960年开始，LiDAR应用在测量中，目前有卫星LiDAR(IceSat)&lt;/p&gt;

&lt;p&gt;https://icesat-2.gsfc.nasa.gov/science/data-products&lt;/p&gt;

&lt;p&gt;机载LiDAR，UVA(无人机)LiDAR，车载LiDAR，Terrestrial (total station or static) LiDAR与室内LiDAR等，下面主要对机载LiDAR进行说明。&lt;/p&gt;

&lt;h2 id=&quot;扫描原理&quot;&gt;扫描原理&lt;/h2&gt;

&lt;p&gt;由于在处理LiDAR点云的过程中，一直处理的是LiDAR坐标信息，以为LiDAR大都是线阵扫描的，实际上还有很多是圆形扫描的，比如Leica TerrainMapper。扫描方式与镜面的旋转方式有关，对于获得的点云来说，会影响到点云的密度，扫描的角度的大小等。&lt;/p&gt;

&lt;p&gt;扫描方式有：zigzag扫描，线性扫描，圆形扫描，Terrestrial LiDAR 扫描等。&lt;/p&gt;

&lt;p&gt;最后，如有不对的地方，请批评指正。&lt;/p&gt;</content><author><name></name></author><category term="markdown" /><summary type="html">LiDAR测量原理</summary></entry><entry><title type="html">核线影像的坐标转换</title><link href="https://whuwuteng.github.io/personal_page/markdown/2024/02/09/epi.html" rel="alternate" type="text/html" title="核线影像的坐标转换" /><published>2024-02-09T00:00:00-06:00</published><updated>2024-02-09T00:00:00-06:00</updated><id>https://whuwuteng.github.io/personal_page/markdown/2024/02/09/epi</id><content type="html" xml:base="https://whuwuteng.github.io/personal_page/markdown/2024/02/09/epi.html">&lt;h1 id=&quot;核线影像的坐标转换&quot;&gt;核线影像的坐标转换&lt;/h1&gt;

&lt;h2 id=&quot;核线影像介绍&quot;&gt;核线影像介绍&lt;/h2&gt;

&lt;p&gt;核线影像（Epipolar image）是摄影测量的概念，可以看到计算机视觉不是这个说法，叫什么&lt;a href=&quot;https://zh.wikipedia.org/wiki/%E5%AF%B9%E6%9E%81%E5%87%A0%E4%BD%95&quot;&gt;对极几何&lt;/a&gt;。当然，不管怎么叫法，都是一样的，指同名点在同一条直线上。&lt;/p&gt;

&lt;p&gt;记得在摄影测量的课程上是通过左右影像的水平核线采样实现的，可以参考摄影测量的教材，这个方法对于航空影像和卫星影像适用，但是，对于拍摄角度相差较大时，产生的变形太大，目前都是用计算机视觉的方法，可以参考《Multiple_View_Geometry_in_Computer_Vision》。&lt;/p&gt;

&lt;h2 id=&quot;核线影像坐标到原始影像&quot;&gt;核线影像坐标到原始影像&lt;/h2&gt;

&lt;p&gt;通过计算机视觉的方法，计算出homography矩阵对影像进行变换。实际应用上，得到的是影像新的旋转矩阵，在个变换过程中，相当于影像有了新的外方位元素，焦距也是没有变的：&lt;strong&gt;核线影像有新的内外方位元素&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;实际上，外方位元素也只有旋转矩阵发生变化，如果不考虑多视交会，可以直接用新的内外方位元素计算三位坐标。这个地方也是与摄影测量不同的地方，就是用摄影测量的方法，&lt;strong&gt;核线影像是一个临时的，没有定位信息&lt;/strong&gt;，密集匹配结果要转换到原始影像才能计算三维坐标。&lt;/p&gt;

&lt;p&gt;如果涉及核线影像的坐标到原始影像的坐标，那就是涉及到一个变换 ：&lt;/p&gt;

&lt;h4 id=&quot;相机的位置不变只是旋转矩阵变化了&quot;&gt;&lt;strong&gt;相机的位置不变，只是旋转矩阵变化了&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;这个问题也设计到&lt;a href=&quot;https://en.wikipedia.org/wiki/Image_stitching&quot;&gt;全景影像&lt;/a&gt;的拼接，实质是一样的，可以参考&lt;a href=&quot;https://courses.cs.washington.edu/courses/cse576/05sp/papers/MSR-TR-2004-92.pdf&quot;&gt;文档&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&quot;几何变换&quot;&gt;几何变换&lt;/h2&gt;

&lt;p&gt;具体几何变换可以参考《Multiple_View_Geometry_in_Computer_Vision》8.4.5和《Computer Vision: Algorithms and Applications》的Mapping from one camera to another&lt;/p&gt;

&lt;p&gt;公式为：
&lt;span class=&quot;katex-error&quot; title=&quot;ParseError: KaTeX parse error: No such environment: align at position 7: \begin{̲a̲l̲i̲g̲n̲}̲
x_2=K_2 R_2 R_…&quot; style=&quot;color:#cc0000&quot;&gt;\begin{align}
x_2=K_2 R_2 R_1^{-1} K_1^{-1} x_1
\end{align}&lt;/span&gt;
其中$x_1$是在核线影像（相机1）的坐标，$K_1$是核线影像（相机1）的内方位矩阵，$R_1$是核线影像（相机1）的旋转矩阵，$K_2$是原始影像（相机2）的内方位矩阵，$R_2$是原始影像（相机2）的旋转矩阵。&lt;/p&gt;

&lt;p&gt;下面是主要的代码，依赖Eigen :&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;// epi_xx是核线影像对应的参数
// org_xx是原始影像对应的参数
Eigen::Vector2d GlobTransfoEpip(Eigen::Vector2d epixy, CImgCameraIOP * pEpiCameraIop, Eigen::Matrix3d epiExtrinsicRotate, CImgCameraIOP * pOrgCameraIop, Eigen::Matrix3d orgExtrinsicRotate)
{
    double x3 = 0;
    double y3 = 0;
    // K-1 * x
    pEpiCameraIop-&amp;gt;Image2World(epixy(0), epixy(1), &amp;amp; x3, &amp;amp; y3);

    Eigen::Vector3d worldxyz;
    worldxyz(0) = x3;
    worldxyz(1) = y3;
    worldxyz(2) = 1.0;

    Eigen::Vector3d aC = epiExtrinsicRotate.inverse() * worldxyz;
    Eigen::Vector3d orgxyz = orgExtrinsicRotate * aC;

    double worldx = orgxyz(0)/orgxyz(2);
    double worldy = orgxyz(1)/orgxyz(2);

    double x = 0;
    double y = 0;

	// K * x
    pOrgCameraIop-&amp;gt;World2Image(worldx, worldy, &amp;amp; x, &amp;amp; y);

    Eigen::Vector2d orgxy;
    orgxy(0) = x;
    orgxy(1) = y;

    return orgxy;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;最后，如有不对的地方，请批评指正。&lt;/p&gt;</content><author><name></name></author><category term="markdown" /><summary type="html">核线影像的坐标转换</summary></entry><entry><title type="html">招收摄影测量与计算机视觉研究生</title><link href="https://whuwuteng.github.io/personal_page/markdown/2023/10/01/phd.html" rel="alternate" type="text/html" title="招收摄影测量与计算机视觉研究生" /><published>2023-10-01T00:00:00-05:00</published><updated>2023-10-01T00:00:00-05:00</updated><id>https://whuwuteng.github.io/personal_page/markdown/2023/10/01/phd</id><content type="html" xml:base="https://whuwuteng.github.io/personal_page/markdown/2023/10/01/phd.html">&lt;h1 id=&quot;招收摄影测量与计算机视觉研究生&quot;&gt;招收摄影测量与计算机视觉研究生&lt;/h1&gt;

&lt;h2 id=&quot;导师介绍&quot;&gt;导师介绍&lt;/h2&gt;

&lt;p&gt;吴腾(Teng Wu)博士目前是法国国家地理林业信息研究所(Institut national de l’information géographique et forestière, IGN)的LASTIG组研究员，分别于2016年和2011年在武汉大学遥感信息工程学院取得博士与学士学位。之后，于2017年到2018年，在武汉大学测绘遥感国家重点实验室从事博士后研究，之后于2018年到2023年在IGN的LASTIG从事博士后研究，合作导师是Bruno  Vallet， Marc Pierrot-Deseilligny和Cédric Demonceaux(Université de Bourgogne，勃艮第大学)。&lt;/p&gt;

&lt;p&gt;Google scholar : https://scholar.google.com/citations?user=QC4Qb2sAAAAJ&amp;amp;hl=zh-CN&lt;/p&gt;

&lt;p&gt;主页 : https://www.umr-lastig.fr/WU-Teng/&lt;/p&gt;

&lt;p&gt;目前在准备法国的HDR(habilitation à diriger des recherches)的资格，因此不能独立带博士，所以博士的导师会是Bruno  Vallet(大概率)，我会负责具体的指导。&lt;/p&gt;

&lt;h2 id=&quot;研究方向&quot;&gt;研究方向&lt;/h2&gt;

&lt;p&gt;LiDAR点云数据处理（包括机载与车载）&lt;/p&gt;

&lt;p&gt;影像密集匹配&lt;/p&gt;

&lt;p&gt;影像与LiDAR点云配准&lt;/p&gt;

&lt;p&gt;变化检测&lt;/p&gt;

&lt;p&gt;三维重建&lt;/p&gt;

&lt;h2 id=&quot;申请条件&quot;&gt;申请条件&lt;/h2&gt;

&lt;p&gt;在摄影测量、计算机视觉等相关领域取得硕士学位&lt;/p&gt;

&lt;p&gt;具有良好的编程能力&lt;/p&gt;

&lt;p&gt;具有良好的英语表达能力和写作能力(会法语更好)&lt;/p&gt;

&lt;p&gt;独立自主，踏实认真&lt;/p&gt;

&lt;h2 id=&quot;研究所与法国博士介绍&quot;&gt;研究所与法国博士介绍&lt;/h2&gt;

&lt;p&gt;IGN是位于巴黎大区(1号线末端)的测绘研究单位，负责全法国的地理信息数据，IGN有自己的飞机和飞机场，会采集全法国的数据，包括每3年全法国的航空数据采集与生产，全法国密集LiDAR点云的采集与生产，全法国地图的生产等；IGN和CNES在Toulouse有合作地面卫星数据接受中心，会生产卫星数据；有法国最好的地理信息工程师学校ENSG-géomatique(École nationale des sciences géographiques)。LASTIG是IGN负责科研的部门，有开源摄影测量软件MicMac，主要从事摄影测量与计算机视觉的研究。&lt;/p&gt;

&lt;p&gt;另外，由于IGN的特殊性，不能招收CSC的学生。由于法国的博士生是合同制，在岗位说明之后才知道具体的工作。如果有合适的话，在岗位出来之后，会通知申请。&lt;/p&gt;

&lt;p&gt;根据法国的规则，具有HDR资格的老师大多只能同时带3个左右(如果是30%的话)的博士生，因此博士的导师也会负责指导工作，所以也希望能了解一下Bruno  Vallet的研究方向。另外一方面，这也说明博士岗位也不多，因此希望能相多了解。&lt;/p&gt;</content><author><name></name></author><category term="markdown" /><summary type="html">招收摄影测量与计算机视觉研究生</summary></entry><entry><title type="html">法国学术职位经验</title><link href="https://whuwuteng.github.io/personal_page/markdown/2023/09/05/concours.html" rel="alternate" type="text/html" title="法国学术职位经验" /><published>2023-09-05T00:00:00-05:00</published><updated>2023-09-05T00:00:00-05:00</updated><id>https://whuwuteng.github.io/personal_page/markdown/2023/09/05/concours</id><content type="html" xml:base="https://whuwuteng.github.io/personal_page/markdown/2023/09/05/concours.html">&lt;h1 id=&quot;法国学术职位经验&quot;&gt;法国学术职位经验&lt;/h1&gt;

&lt;h2 id=&quot;学术岗位介绍&quot;&gt;学术岗位介绍&lt;/h2&gt;

&lt;p&gt;写这篇博文的目的是给其他需要在法国找学术职位的人一些经验和参考，希望对还在法国学术圈挣扎的人一些帮助，只讨论学术岗位，其他不在讨论范围内。&lt;/p&gt;

&lt;p&gt;法国的初级学术岗位(博士毕业或博后申请)主要有三种：Chargé de recherche，Enseignant-chercheur(maître de conférence)，Ingénieur de recherche，其他的就是研究的辅助岗位，不详细说了，可以参考&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;。&lt;/p&gt;

&lt;p&gt;这个其中区别，也要看具体的研究单位，比如CNRS和Inria，Chargé de recherche和Ingénieur de recherche是完全区分的，Ingénieur de recherche只是作为Chargé de recherche的辅助，所以他们的concours是分开的，详细可以参考CNRS的Chargé de recherche的concours&lt;sup id=&quot;fnref:2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;和Ingénieur de recherche的concours&lt;sup id=&quot;fnref:3&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;。在有些研究单位，大部分研究人员(主要工作是指导博士生和申请项目)都是Ingénieur de recherche，只有极少数人是Chargé de recherche，如CEA&lt;sup id=&quot;fnref:4&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;和ONERA&lt;sup id=&quot;fnref:5&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:5&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt;，CEA中也有Ingénieur de recherche不带学生发文章的。也有单位很模糊的，比如我们单位，有的人是Ingénieur，有的人有时候做Chargé de recherche的工作， 有时候做Enseignant-chercheur的工作；有的人做纯工程师的工作；有的人做工程师的工作之外，做一点研究(不多)，基本不发文章，没有博士生。不过，我是后来才知道的，这种Ingénieur的工资的计算是比chargé de recherche高的。我们是研究单位，研究部门中的研究人员有两部分组成，一部分是单位内的研究人员，进来时是Ingénieur(这个和法国精英教育体制有关系)，另一部分是Ministère de la Transition énergétique的，进来时是Chargé de recherche，要通过concours，进来时是有编制的(在法国叫fonctionnaire)。&lt;/p&gt;

&lt;p&gt;Enseignant-chercheur(maître de conférence)对应学校的副教授岗位，maître de conférence相当于是有编制(在法国叫fonctionnaire)的Enseignant-chercheur，是通过GALAXIE&lt;sup id=&quot;fnref:6&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:6&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;6&lt;/a&gt;&lt;/sup&gt; 招的，则是有编制的，不过前提是要通过一年一次的qualification&lt;sup id=&quot;fnref:7&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:7&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;7&lt;/a&gt;&lt;/sup&gt;，明年等我他通过了，可能会写一个详细的介绍。Enseignant-chercheur一般指单位自己招的，就是没有编制(也是CDI永久岗位)。相对来说，在法国这样的岗位比纯研究岗位多很多，因为他们一年有192h的上课任务。我们单位有一个école，因此又有一部分Enseignant-chercheur，但是很多Enseignant-chercheur的人都因为长期不参加研究项目，最后都成为纯Enseignant了。这个要说一下，法国大学也有只教学的岗位，一年有384h的上课任务，相当于是已经离开了科研了。&lt;/p&gt;

&lt;h2 id=&quot;背景介绍&quot;&gt;背景介绍&lt;/h2&gt;

&lt;p&gt;我自己是国内本科+直博，在法国一个研究所做博士后，考虑到目前方向在巴黎没有其他的单位，家庭的因素，而且如果去计算机专业竞争学术岗位基本也没有机会，因此目前的研究所是我的首选。下面，我将对整个过程中经历和感受作介绍，希望给大家一些帮助。&lt;/p&gt;

&lt;h3 id=&quot;chargé-de-recherchefonctionnaire&quot;&gt;Chargé de recherche(fonctionnaire)&lt;/h3&gt;

&lt;p&gt;在2023年初，我们组(博后导师是组的leader)要招一个研究岗，但是由于导师生病，半年(从招聘开始到结束)都没来单位上班，这也给申请过程中带来了一些困难。这个岗位是Ministère de la Transition énergétique(MTE)的Chargé de recherche，可以通过网站&lt;sup id=&quot;fnref:8&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:8&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;8&lt;/a&gt;&lt;/sup&gt;报名，一般是二月开始，然后大概一个月结束。在网站上有详细的介绍，根据材料的说明进行准备。&lt;/p&gt;

&lt;p&gt;提交材料中主要包括博士的论文评审答辩材料，这个在法国很关键，我是通过学校的档案馆拿到之后翻译的，其他的有学术生涯的总结等。这个其中最关键的是projet de recherche，有点类是国内的申请项目书。这个projet de recherche要根据岗位申请说明来，一般来说，研究工作都是一个很大的范围，要联系写这个岗位申请的人。在fichie de poste(岗位介绍)中，通常有多个(3-4)联系人，通常找组leader联系是比较稳妥的，lab的leader有可能对合作经费等方面更在意。&lt;/p&gt;

&lt;p&gt;材料上交之后就是等面试了，面试的时间是严格控制在30分钟的，个人的presentation是15分钟，然后回答问题15分钟。个人的prensentation主要是自己的介绍，包括研究经历、文章、教学等，然后主要是projet de recherche(感觉10分钟左右)。跟普通的面试差不多，就是基于科研、教学和projet de recherche的问题。要注意的是，就算是研究岗位，也是有教学任务的，一年是64h的教学任务，所以教学经历最好也是有的。&lt;/p&gt;

&lt;p&gt;这个过程中的经验是：&lt;/p&gt;

&lt;p&gt;（1）由于岗位的工资来至于MTE，因此招聘单位在jury当中没有发言权。对于我这种情况，已经在招聘单位工作，招聘单位的人不会给意见(我的导师多次说他不能帮我更多了，因为要保证公平性)。jury是由跟单位无任何利益关系的人组成的，一般由7个左右，最后那天招聘单位去2个人，只是去旁听，不会提问，也不会跟其他的jury提意见。当然，招聘单位是有最后的决定权的，他们可以选择一个也不要，也可以选择要liste中的其他人，我记得一个中国的名字在面试之后排在第一，但是最后的结果确实第二，这个可能是招聘单位的意见。但是招聘单位一般不会这样做，因为他们要给一个说服MTE的理由。&lt;/p&gt;

&lt;p&gt;（2） 根据联系人给的信息之后，准备projet de recherche，这个比较关键，跟自己的研究经历有关或者连续性的研究项目。类似于研究计划，但是感觉跟项目申请书更像，就是写自己打算做啥，有什么创新等，这个研究计划在15页内就可以了。从(1)中可以看出来，jury并不是很清楚单位需要什么人，所以尽量在研究范围内跟自己的研究方向深入的写。因为我导师是组的leader，所以我最清楚要招什么人。但是我在prensentation中提出，我的研究计划正好是延续一个离开的Chargé de recherche的研究内容时，一个jury表示反对，我感觉我对jury那个问题回答并不好。准备的过程中，导师觉得这个理所当然，但是jury觉得这个不合理，我也不知道怎么解释。&lt;/p&gt;

&lt;p&gt;（3）在法国，博士毕业之后去其他研究所(或者出法国)对法国竞争岗位也是很关键的，这一项也是考察范围。&lt;/p&gt;

&lt;p&gt;（4）面试可以用法语或英语。我在自我介绍时用的发育，后面到技术部分用的英语，回答问题也是用的英语。不过，有个人还是让我用法语总结自己的教学部分，所以法语对他们还是很关键的。&lt;/p&gt;

&lt;p&gt;（5）在jury当中，只有1-2个人跟自己的专业是相关(只是相关，研究方法会有很大的差异)，所以在介绍projet de recherche最好是能简单一些，就是能让其他专业的人也能听懂。&lt;/p&gt;

&lt;p&gt;（6）在做prensentation的那部分，尽量熟练。由于英语和法语不是母语，对于我自己有一些困难。同时因为我自己的原因，所以交流一直是我的问题。但是我发现，把slide做好后，然后开始写稿，一步步去精华台词，最后发现可以无意识的把后面一句说出来，在做prensentation时不会太紧张。&lt;/p&gt;

&lt;p&gt;（7）单位的人不会透露你竞争对象是谁，我也是最后一天面试的时候看到他我才知道是谁的，因为他是我们单位毕业的博士，我有一些印象。&lt;/p&gt;

&lt;p&gt;结果：&lt;/p&gt;

&lt;p&gt;在差不多两周之后就出面试结果，面试结果之后一个月，会公布最后的结果，这些结果都是发布到网站上，并不会发邮箱通知。&lt;/p&gt;

&lt;p&gt;我知道我面试排第二时，还是很失落的，不过还是希望通过这些经验，能给大家一些帮助。&lt;/p&gt;

&lt;h3 id=&quot;directeur-de-recherche-juniorcdd&quot;&gt;Directeur de recherche junior(CDD)&lt;/h3&gt;

&lt;p&gt;在2023年5月，在实验室另外一个组要招一个directeur de recherche junior&lt;sup id=&quot;fnref:9&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:9&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;9&lt;/a&gt;&lt;/sup&gt;，这个岗位在大学中对应是 la chaire de professeur junior。由于我们单位是研究单位，所以是研究员性质的，而不是教授性质的。它是一个tenure track，要求是3-6年要拿到博导资格(habilitation à diriger des recherches, HDR)，之后就是CDI了。这个岗位是学美国的，对于法国人获得CDI的教职岗位并不难，所以它对CDI的教职也有它的优势：（1） 有启动研究基金，可以入职的时候招2个博士生。这个要说明，在法国招博士生是很难的，要有经费，我看到很多Chargé de recherche到6-7年都没有一个博士生的。（2）拿到HDR之后，可以直接有Directeur de recherche或professeur的岗位的，这条很关键，因为在法国有很多人有HDR，但是一直还是Chargé de recherche或Enseignant-chercheur的。&lt;/p&gt;

&lt;p&gt;这个岗位提交材料准备相对Chargé de recherche简单一些，网站&lt;sup id=&quot;fnref:9:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:9&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;9&lt;/a&gt;&lt;/sup&gt;上有个表和研究与教学计划，就可以提交了。对于研究计划和教学计划要跟fichie de poste(岗位介绍)中的联系人咨询，而且要求很短，研究计划3页内(比Chargé de recherche的15页少很多)，其实就是自己想做啥，其他的啥都写不了；教学计划2页内。&lt;/p&gt;

&lt;p&gt;提交材料之后，大概半个月会有通知面试，这个面试是有一些特点的，因为其实Directeur de recherche junior的岗位要求是比Chargé de recherche要求高的，在法国，毕竟3-6年要拿到HDR是很难的，因此一般都是做了几年的博士后申请的，而Chargé de recherche是博士毕业就可以申请了，很多都法国博士一毕业就拿到了Chargé de recherche的。&lt;/p&gt;

&lt;p&gt;面试时间是1个小时：10分钟介绍自己和研究计划，5分钟一个上课的演示，注意上课演示的slide只有一页。然后就是45分钟的回答问题，根据我的经历，由于大家都做研究很久了，反而研究上的问题少，而指导学生的问题多(由于这个是研究岗，如果是大学的话，可能是教学了)。因为在法国，博士后临时工是没有资格申请项目的，所以大家也不会问这个经历。&lt;/p&gt;

&lt;p&gt;这个过程中的经验：&lt;/p&gt;

&lt;p&gt;（1）jury有6个人左右，还有有一个非法国人，我面试时是Christian Heipke，然后本单位2个人，其他就是其他单位了。我面试时jury是我们的école的directeur(校长)，很多人都是这个专业的人，我导师告诉我5个人是他认识的。&lt;/p&gt;

&lt;p&gt;（2）单位的人不会透露你竞争对象是谁，这个印象很深刻。他们好像怕你知道似的，让你在一个办公室等，一直等面试的人走了，才让你出来去面试的办公室。&lt;/p&gt;

&lt;p&gt;（3）面试中指导学生的问题很多，我记得有2个jury提的问题跟这个有关，Christian Heipke问了好几个这个问题，我发现他确实很nice，所以怎么带学生这个问题要多思考。&lt;/p&gt;

&lt;p&gt;（4）由于有一个非法国人，因此面试要用英语，当然在上课演示可以用法语，应该建议用英语的。&lt;/p&gt;

&lt;p&gt;（5）上课的模拟也是很关键的，邮件中有说明，貌似获得岗位之后，有一个课程就是这个内容，大概5周，每周3h，对应的法国的是cours。所以这个5分钟是一个课程内容和计划。&lt;/p&gt;

&lt;p&gt;最后的结果是打电话通知的，没有排名，估计是和申请者敲定之后才通知我没有被选择。从跟实验室的leader聊天的过程，他告诉我，那个申请者已经是maître de conférence，他有项目，有学生，因此他们觉得他比我更容易获得HDR。至于别人为啥要抛弃fonctionnaire来竞争tenure track，是因为他们maître de conférence一年有192h的教学任务，而Directeur de recherche junior只有64h的教学任务，而且别人相信自己3-5年可以获得HDR。这也是为啥很多Enseignant-chercheur很多最后都变成了纯的Enseignant，可能那么多教学之后，就没有多少精力去做研究了。&lt;/p&gt;

&lt;p&gt;最后希望自己的经历能给大家一些帮助。&lt;/p&gt;

&lt;h3 id=&quot;enseignant-chercheurcdi&quot;&gt;Enseignant-chercheur(CDI)&lt;/h3&gt;

&lt;p&gt;并不是所有的Enseignant-chercheur都是通过GALAXIE&lt;sup id=&quot;fnref:6:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:6&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;6&lt;/a&gt;&lt;/sup&gt; (大学)招的，也有école自己在自己的网站上招聘的。注意，在法国大学一般都是几个école组成的，我想是因为针对排名想出来的办法，école对应以前的工程师学校。对法国的科研岗位了解后，感觉我可能不太适合Enseignant-chercheur的岗位，就只在最相关的方向投了2个岗位。&lt;/p&gt;

&lt;p&gt;在2023年3月，我无意看到一个学校招聘的方向和我的背景还有一些相似，当时也没有报太大的指望，就投了。跟其中一个人(研究组leader)联系的过程中，发现他们对教学很看重，那个人建议我去做一个presentation，然后好讨论怎么写材料。由于我当时在准备Chargé de recherche的材料，本来没有多少精力去准备，所以就没有去做presentation。&lt;/p&gt;

&lt;p&gt;Enseignant-chercheur准备的材料和Chargé de recherche的材料基本差不多，就是研究经历、文章、教学等，在加上研究计划和教学计划，当然关键的是教学经历和教学计划。&lt;/p&gt;

&lt;p&gt;在6月初，其中一个回复说，因为申请者太少了，所以就不招了。对另一个岗位，一直没有消息，我最后就问了一下他们，他们的回复说他们选择另外一个人，那个让的教学经历更丰富。&lt;/p&gt;

&lt;p&gt;这个过程中，我才知道，在法国有普通的博士生合同中有上课时间，有 chargé d’enseignement vacataire&lt;sup id=&quot;fnref:10&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:10&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;10&lt;/a&gt;&lt;/sup&gt;，还有一种ATER&lt;sup id=&quot;fnref:11&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:11&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;11&lt;/a&gt;&lt;/sup&gt;，类是CDD的Enseignant-chercheur，一年192h的教学任务，它跟maître de conférence一起开始招聘，通过这个可以增加教学经验。同时，有的学校还有CDD的全职Enseignant，这样也可以提高教学经验。虽然ATER可以增加教学经验，但是教学经验只是必要条件，也有做过ATER也找不到Enseignant-chercheur岗位的。&lt;/p&gt;

&lt;p&gt;由于maître de conférence需要通过qualification&lt;sup id=&quot;fnref:7:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:7&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;7&lt;/a&gt;&lt;/sup&gt;，我错过了2023年的材料提交时间，因此我没有资格通过大学的招聘。我打算2024年把材料提交上去，等我通过之后，我将会详细写一下怎么申请qualification。&lt;/p&gt;

&lt;h2 id=&quot;结束语&quot;&gt;结束语&lt;/h2&gt;

&lt;p&gt;之所以把这段话放到最后，是不想浪费大家的时间。由于自己性格上的问题，当时其实在国内已经在做博后了，明白国内的科研环境对自己也很不利，所以在毅然选择出国，尤其到了法国一个完全陌生的国家。当时还不知道大家不讲英语(博后导师是一个乐观的人，跟我说不说英语在法国也可以)，而我到法国时，连bonjour都不会说。由于自身的条件(国内的博士等)和法语的因素，让我在回国和留在这边思考了很久，最后才下定决心好好学法语留下。中间由于covid，又缺乏语言环境，因此，即使接近5年，法语还是没能让人满意。&lt;/p&gt;

&lt;p&gt;由于我是直博，在众多横向项目中，锻炼出了对专业中流程的大部分都很熟悉，后来发现，这样的背景比较适合目前的研究所，他们也希望有更多经验的人。在第二个合同开始后，导师流露出想留我的意思，也增加了我在整个申请过程中的信心。&lt;/p&gt;

&lt;p&gt;当然，经过这些失败，我自己觉得自己有一些问题，因为我说话有口吃，尤其在紧张时明显，在加上英语和法语不是母语，就更明显了。虽然在presentation阶段因为准备充分，没有问题，但是回答问题阶段，问题就暴露出来了，再加上法语我也很不熟练，因此在Chargé de recherche的concours中没成功(单位的一个旁听者的意见)。第二次面试是Directeur de recherche junior，有了第一次的经验之后，我感觉紧张少了一些，我在面试中开始开始观察jury的表情，这个里我想说的是，多次练习面试也可以提高的表现的，即使对于口吃的人。&lt;/p&gt;

&lt;p&gt;后来导师给出了解决办法(主要是école的directeur是我的一个面试的jury，他也是提出解决办法的人)，还是留下来了，不过在我的心中有一种很难用言语说出来的滋味，感觉不是靠自己获得的。考虑我跟另外一个导师的一次对话，他告诉我由于经济原因，目前研究所只有人退休才会有新的人进来，最近几年有可能没有新的岗位，因此最后接受导师的好意，心存感激。&lt;/p&gt;

&lt;p&gt;还有一点，最好不要在6月合同结束的时候还没找到下家，因为我是今年上半年在忙申请岗位的事情，而且导师说我的proposal写的挺好的，所以我当时就没仔细去找下家，后来发现两个岗位都没上，就失业在家了。而且新的岗位又是临时想出来的岗位，因此中间等了好几个月。在得到消息之前，我尝试去找，由于家庭原因，在巴黎这个区域真是很难找到，而且7-8月法国人基本都不上班了，发邮件很少有回复，可能大家放假回来之后觉得这个邮件太久了，所以就不回复了。后来听说，要到9-10月才是博士后岗位出来的高峰。&lt;/p&gt;

&lt;h2 id=&quot;参考&quot;&gt;参考&lt;/h2&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://www.enseignementsup-recherche.gouv.fr/fr/les-personnels-de-la-recherche-46556 &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://www.cnrs.fr/fr/concours-ch &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://www.cnrs.fr/fr/concours-it &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:4&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://www.cea.fr/recrutement/ &lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:5&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://www.onera.fr/fr/recherche-onera &lt;a href=&quot;#fnref:5&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:6&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://www.galaxie.enseignementsup-recherche.gouv.fr/ensup/candidats.html &lt;a href=&quot;#fnref:6&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt; &lt;a href=&quot;#fnref:6:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:7&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://www.galaxie.enseignementsup-recherche.gouv.fr/ensup/cand_qualification_droit_commun.htm &lt;a href=&quot;#fnref:7&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt; &lt;a href=&quot;#fnref:7:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:8&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://www.concours.developpement-durable.gouv.fr/charge-e-de-recherche-du-developpement-durable-de-a126.html &lt;a href=&quot;#fnref:8&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:9&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://www.galaxie.enseignementsup-recherche.gouv.fr/ensup/cand_CPJ.htm &lt;a href=&quot;#fnref:9&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt; &lt;a href=&quot;#fnref:9:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:10&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://www.galaxie.enseignementsup-recherche.gouv.fr/ensup/etab_autres_contractuels_ES.htm &lt;a href=&quot;#fnref:10&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:11&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://www.education.gouv.fr/attache-temporaire-d-enseignement-et-de-recherche-ater-12767 &lt;a href=&quot;#fnref:11&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name></name></author><category term="markdown" /><summary type="html">法国学术职位经验</summary></entry><entry><title type="html">Visualization</title><link href="https://whuwuteng.github.io/personal_page/markdown/2022/09/05/tSNE.html" rel="alternate" type="text/html" title="Visualization" /><published>2022-09-05T00:00:00-05:00</published><updated>2022-09-05T00:00:00-05:00</updated><id>https://whuwuteng.github.io/personal_page/markdown/2022/09/05/tSNE</id><content type="html" xml:base="https://whuwuteng.github.io/personal_page/markdown/2022/09/05/tSNE.html">&lt;h1 id=&quot;visualization&quot;&gt;Visualization&lt;/h1&gt;

&lt;p&gt;A picture is worth a thousand words&lt;sup id=&quot;fnref:13&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:13&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;sup id=&quot;fnref:14&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:14&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;。&lt;/p&gt;

&lt;p&gt;tSNE是一个显示工具，可以参考论文&lt;sup id=&quot;fnref:9&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:9&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;。&lt;/p&gt;

&lt;p&gt;深度学习中的数据的相似性是很关键，对于transfer learning 或者domain adaption显得比较关键。发现tSNE&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;是一个显示多维特征的工具，是基于最小 Kullback-Leibler divergence&lt;sup id=&quot;fnref:2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt;的降维工具，通常与PCA&lt;sup id=&quot;fnref:3&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;6&lt;/a&gt;&lt;/sup&gt;进行比较&lt;sup id=&quot;fnref:4&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;7&lt;/a&gt;&lt;/sup&gt;。对于Curse of Dimensionality，当维数太大，会有问题&lt;sup id=&quot;fnref:7&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:7&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;8&lt;/a&gt;&lt;/sup&gt;。&lt;/p&gt;

&lt;h2 id=&quot;kullback-leibler-divergence&quot;&gt;Kullback-Leibler divergence&lt;/h2&gt;

&lt;p&gt;KL divergence可以看作是描述两组数据的分布的一致性，有点类似与互信息（MI）&lt;sup id=&quot;fnref:5&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:5&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;9&lt;/a&gt;&lt;/sup&gt;，但是MI与KL divergence并不等价&lt;sup id=&quot;fnref:10&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:10&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;10&lt;/a&gt;&lt;/sup&gt;，有点类似于表达两个分布的差异，而且结果是非对称的&lt;sup id=&quot;fnref:6&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:6&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;11&lt;/a&gt;&lt;/sup&gt;。&lt;/p&gt;

&lt;p&gt;另外，KL divergence可以作为目标函数&lt;sup id=&quot;fnref:11&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:11&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;12&lt;/a&gt;&lt;/sup&gt;，在pytorch中有实现&lt;sup id=&quot;fnref:12&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:12&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;13&lt;/a&gt;&lt;/sup&gt;。&lt;/p&gt;

&lt;h2 id=&quot;tsne&quot;&gt;tSNE&lt;/h2&gt;

&lt;p&gt;tSNE 主要是多维特征的显示&lt;sup id=&quot;fnref:4:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;7&lt;/a&gt;&lt;/sup&gt;，利用KL divergence作为目标函数，用 stochastic gradient descent进行优化&lt;sup id=&quot;fnref:7:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:7&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;8&lt;/a&gt;&lt;/sup&gt;，而且可能多次运行的结果并不一样&lt;sup id=&quot;fnref:8&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:8&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;14&lt;/a&gt;&lt;/sup&gt;。&lt;/p&gt;

&lt;p&gt;网上有一个GUI的例子，显示迭代次数与显示结果的关系&lt;sup id=&quot;fnref:8:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:8&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;14&lt;/a&gt;&lt;/sup&gt;。&lt;/p&gt;

&lt;h2 id=&quot;feature-visualization&quot;&gt;Feature visualization&lt;/h2&gt;

&lt;p&gt;对于CNN中间layer的分析，发现CNN有translationally invariant，但是没有rotationally invariant&lt;sup id=&quot;fnref:15&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:15&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;15&lt;/a&gt;&lt;/sup&gt;。有对应的基于pytorch的代码&lt;sup id=&quot;fnref:16&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:16&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;16&lt;/a&gt;&lt;/sup&gt;。同时，在pytorch的forum上也有学多feature visualization的讨论&lt;sup id=&quot;fnref:17&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:17&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;17&lt;/a&gt;&lt;/sup&gt;。&lt;/p&gt;

&lt;p&gt;常用的做法都是用hook函数，直接显示layer的output&lt;sup id=&quot;fnref:18&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:18&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;18&lt;/a&gt;&lt;/sup&gt;。&lt;/p&gt;

&lt;h2 id=&quot;footnotes&quot;&gt;Footnotes&lt;/h2&gt;
&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:13&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://en.wikipedia.org/wiki/A_picture_is_worth_a_thousand_words. &lt;a href=&quot;#fnref:13&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:14&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://towardsdatascience.com/the-art-of-effective-visualization-of-multi-dimensional-data-6c7202990c57. &lt;a href=&quot;#fnref:14&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:9&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://lvdmaaten.github.io/tsne/. &lt;a href=&quot;#fnref:9&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html. &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence. &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://en.wikipedia.org/wiki/Principal_component_analysis. &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:4&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://medium.com/analytics-vidhya/note-visualize-multi-dimension-datasets-in-a-2d-graph-using-t-sne-airbnb-bookings-dataset-as-824541cc5388. &lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt; &lt;a href=&quot;#fnref:4:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:7&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://jotterbach.github.io/content/posts/tsne/2016-05-23-TSNE/. &lt;a href=&quot;#fnref:7&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt; &lt;a href=&quot;#fnref:7:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:5&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;http://www.scholarpedia.org/article/Mutual_information. &lt;a href=&quot;#fnref:5&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:10&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://stats.stackexchange.com/questions/487012/are-mutual-information-and-kullback-leibler-divergence-equivalent. &lt;a href=&quot;#fnref:10&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:6&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://zhuanlan.zhihu.com/p/425693597. &lt;a href=&quot;#fnref:6&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:11&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://timvieira.github.io/blog/post/2014/10/06/kl-divergence-as-an-objective-function/. &lt;a href=&quot;#fnref:11&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:12&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://pytorch.org/docs/stable/generated/torch.nn.KLDivLoss.html. &lt;a href=&quot;#fnref:12&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:8&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://distill.pub/2016/misread-tsne/. &lt;a href=&quot;#fnref:8&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt; &lt;a href=&quot;#fnref:8:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:15&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://towardsdatascience.com/how-to-visualize-convolutional-features-in-40-lines-of-code-70b7d87b0030. &lt;a href=&quot;#fnref:15&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:16&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://github.com/fg91/visualizing-cnn-feature-maps. &lt;a href=&quot;#fnref:16&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:17&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://discuss.pytorch.org/t/visualize-feature-map/29597. &lt;a href=&quot;#fnref:17&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:18&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://github.com/lewis-morris/mapextrackt. &lt;a href=&quot;#fnref:18&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name></name></author><category term="markdown" /><summary type="html">Visualization</summary></entry><entry><title type="html">LiDAR and Image in 3D</title><link href="https://whuwuteng.github.io/personal_page/markdown/2022/08/05/LiDAR-and-Image.html" rel="alternate" type="text/html" title="LiDAR and Image in 3D" /><published>2022-08-05T00:00:00-05:00</published><updated>2022-08-05T00:00:00-05:00</updated><id>https://whuwuteng.github.io/personal_page/markdown/2022/08/05/LiDAR-and-Image</id><content type="html" xml:base="https://whuwuteng.github.io/personal_page/markdown/2022/08/05/LiDAR-and-Image.html">&lt;h1 id=&quot;lidar-and-image-in-3d&quot;&gt;LiDAR and Image in 3D&lt;/h1&gt;

&lt;p&gt;LiDAR与image的同时的应用越来越多，很多设备都同时有LiDAR和camera：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/personal_page/images/iPace-lineart-sensor_calloutv2_03022020-01.png&quot; alt=&quot;&quot; title=&quot;waymo car&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;4d-net&quot;&gt;4D-Net&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://ai.googleblog.com/2022/02/4d-net-learning-multi-modal-alignment.html&quot;&gt;4D-Net for Learned Multi-Modal Alignment&lt;/a&gt;用原始的point cloud和image进行训练，获得3D box，比原来把piont cloud转化为map更好一些。&lt;/p&gt;

&lt;h2 id=&quot;lidar-camera-deep-fusion&quot;&gt;&lt;a href=&quot;http://ai.googleblog.com/2022/04/lidar-camera-deep-fusion-for-multi.html&quot;&gt;Lidar-Camera Deep Fusion&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;感觉有个很大的问题是解决&lt;strong&gt;Alignment&lt;/strong&gt;的不一致的问题。&lt;/p&gt;</content><author><name></name></author><category term="markdown" /><summary type="html">LiDAR and Image in 3D</summary></entry><entry><title type="html">Transfer learning in Deep learning</title><link href="https://whuwuteng.github.io/personal_page/markdown/2022/08/04/transfer-learning.html" rel="alternate" type="text/html" title="Transfer learning in Deep learning" /><published>2022-08-04T00:00:00-05:00</published><updated>2022-08-04T00:00:00-05:00</updated><id>https://whuwuteng.github.io/personal_page/markdown/2022/08/04/transfer-learning</id><content type="html" xml:base="https://whuwuteng.github.io/personal_page/markdown/2022/08/04/transfer-learning.html">&lt;h1 id=&quot;transfer-learning-in-deep-learning&quot;&gt;Transfer learning in Deep learning&lt;/h1&gt;

&lt;p&gt;由于loss的非凸性、type的不同，造成Transfer learning在不同的数据、task上表现并没有规律性。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/personal_page/images/VTAB_loss.png&quot; alt=&quot;&quot; title=&quot;VTAB protocol&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;the-visual-task-adaptation-benchmark&quot;&gt;The Visual Task Adaptation Benchmark&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://ai.googleblog.com/2019/11/the-visual-task-adaptation-benchmark.html&quot;&gt;VTAB&lt;/a&gt;基于多种数据、多种任务之间的Transfer learning。&lt;/p&gt;

&lt;p&gt;当数据量增加的时候，从scratch训练，不会有performance的损失。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/personal_page/images/VTAB_scratch.png&quot; alt=&quot;&quot; title=&quot;Performance&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;pretained-models&quot;&gt;Pretained models&lt;/h2&gt;

&lt;p&gt;不能想当然的认为pretained models是有用的，参考&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;，主要的问题有：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;不同的task&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;数据有很大的difference，如果不能share feature，那么不会有什么好处&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;pretained models是local optima，所以会有bias&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;当然，也可以用pretained models做初始值，最后的结果基本也会差不多&lt;sup id=&quot;fnref:2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;。也有文章证明即使是training from scratch&lt;sup id=&quot;fnref:3&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;，结果也不会差很多&lt;sup id=&quot;fnref:4&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;。&lt;/p&gt;

&lt;h2 id=&quot;footnotes&quot;&gt;Footnotes&lt;/h2&gt;
&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://news.ycombinator.com/item?id=33067056. &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://stackoverflow.com/questions/65982245/pretrained-model-or-training-from-scratch-for-object-detection. &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://arxiv.org/abs/1811.08883. &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:4&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://heartbeat.comet.ml/pre-trained-machine-learning-models-vs-models-trained-from-scratch-63e079ed648f. &lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name></name></author><category term="markdown" /><summary type="html">Transfer learning in Deep learning</summary></entry><entry><title type="html">Micmac tools in photogrammetry</title><link href="https://whuwuteng.github.io/personal_page/markdown/2022/07/31/micmac.html" rel="alternate" type="text/html" title="Micmac tools in photogrammetry" /><published>2022-07-31T00:00:00-05:00</published><updated>2022-07-31T00:00:00-05:00</updated><id>https://whuwuteng.github.io/personal_page/markdown/2022/07/31/micmac</id><content type="html" xml:base="https://whuwuteng.github.io/personal_page/markdown/2022/07/31/micmac.html">&lt;h1 id=&quot;micmac-tools-in-photogrammetry&quot;&gt;Micmac tools in photogrammetry&lt;/h1&gt;
&lt;p&gt;Micmac &lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; 是一个摄影测量的开源工具，是基于C++的，可以在Windows和Linux/MacOS X 上运行，由于开发的人主要是Ubuntu，建议在Ubuntu下用。&lt;/p&gt;

&lt;p&gt;Micmac的功能与Colmap&lt;sup id=&quot;fnref:2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; 类似，但是在处理卫星影像数据时，优势是很大的。虽然也有把卫星影像转成Colmap可以处理的类型 &lt;sup id=&quot;fnref:3&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;，Micmac的功能更全，包括Crop、RPC的转换等。&lt;/p&gt;

&lt;h2 id=&quot;build编译&quot;&gt;build(编译)&lt;/h2&gt;

&lt;p&gt;建议在Ubuntu下编译&lt;sup id=&quot;fnref:4&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;，基本不会有配置、运行、编译等错误。&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git clone https://github.com/micmacIGN/micmac.git
&lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;micmac/
&lt;span class=&quot;nb&quot;&gt;mkdir &lt;/span&gt;build
&lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;build
cmake &lt;span class=&quot;nt&quot;&gt;-DWITH_QT5&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1 &lt;span class=&quot;nt&quot;&gt;-DWITH_CPP11&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1 ..
make &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-j4&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;gedit /etc/bash.bashrc
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;PATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/micmac_install_directory/micmac/bin:&lt;span class=&quot;nv&quot;&gt;$PATH&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;aerial-image航空影像&quot;&gt;Aerial image(航空影像)&lt;/h2&gt;

&lt;p&gt;这里的航空影像是指的框幅影像或者叫小孔成像&lt;sup id=&quot;fnref:5&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:5&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt;，对于普通的相机拍摄的都可以处理。之前Github &lt;sup id=&quot;fnref:6&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:6&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;6&lt;/a&gt;&lt;/sup&gt;上已经写了一个详细的流程可以参考。&lt;/p&gt;

&lt;p&gt;在Ubuntu下面显示界面很少， 不过Micmac中有一些显示工具，可以显示影像和输出的结果。&lt;/p&gt;

&lt;h3 id=&quot;vino&quot;&gt;Vino&lt;/h3&gt;

&lt;p&gt;Vino是显示影像的模块：&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Vino Crop-IMG_PHR1B.tif
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;显示feature-point&quot;&gt;显示Feature point&lt;/h3&gt;

&lt;p&gt;可以用SEL这个工具显示：&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;SEL ./ im0.png im1.png &lt;span class=&quot;nv&quot;&gt;KH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;NT
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;写有基于python与wxpython&lt;sup id=&quot;fnref:9&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:9&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;7&lt;/a&gt;&lt;/sup&gt;的工具，是基于keypointgui &lt;sup id=&quot;fnref:10&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:10&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;8&lt;/a&gt;&lt;/sup&gt;开发的，可以支持Micmac的文本和二进制格式  &lt;sup id=&quot;fnref:11&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:11&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;9&lt;/a&gt;&lt;/sup&gt; ：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/personal_page/images/micmac_demo.png&quot; alt=&quot;&quot; title=&quot;feature show&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;显示epipolar&quot;&gt;显示Epipolar&lt;/h3&gt;

&lt;p&gt;核线影像是否没有上下视差受影像的姿态精度决定的，也影响后面密集匹配的结果。&lt;/p&gt;

&lt;p&gt;写有一个基于C++与QT的工具 &lt;sup id=&quot;fnref:8&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:8&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;10&lt;/a&gt;&lt;/sup&gt;，可以显示红/绿映像：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/personal_page/images/eth3d.png&quot; alt=&quot;&quot; title=&quot;red cyan &quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;显示空三结果&quot;&gt;显示空三结果&lt;/h3&gt;

&lt;p&gt;最后显示结果可以用AperiCloud输出结果：&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;AperiCloud &lt;span class=&quot;s2&quot;&gt;&quot;.*tif&quot;&lt;/span&gt; Ori-Compense
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;satellite-image卫星影像&quot;&gt;Satellite image(卫星影像)&lt;/h2&gt;

&lt;p&gt;对于卫星影像，由于很多用RPC作为参数，因此和航空影像的处理有一些区别，有一个详细的流程介绍了卫星影像的处理 &lt;sup id=&quot;fnref:7&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:7&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;11&lt;/a&gt;&lt;/sup&gt; 。&lt;/p&gt;

&lt;p&gt;卫星影像处理除了参数与航空影像不一样之外，内部的原理其实是一致的，因此显示工具基本是可以通用的。&lt;/p&gt;

&lt;h3 id=&quot;crop&quot;&gt;Crop&lt;/h3&gt;

&lt;p&gt;Crop是一个很好的工具，当我们要处理一部分数据，可以减少处理时间，可以用命令：&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;mm3d SateLib CropRPC Ori-satRPC/GB-Orientation-19DEC15WV031000015DEC19142039-P1BS-500514410020_01_P001_________AAE_0AAAAABPABW0.tif.xml Ori-satRPC/GB-Orientation-&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;.xml BenchMark &lt;span class=&quot;nv&quot;&gt;Org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=[&lt;/span&gt;2887,13794] &lt;span class=&quot;nv&quot;&gt;Sz&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=[&lt;/span&gt;13489,34373] 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;footnotes&quot;&gt;Footnotes&lt;/h2&gt;
&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://github.com/micmacIGN/micmac. &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://github.com/colmap/colmap. &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://github.com/Kai-46/ColmapForVisSat. &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:4&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://micmac.ensg.eu/index.php/Install_MicMac_Ubuntu. &lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:5&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://zh.wikipedia.org/wiki/%E9%87%9D%E5%AD%94%E7%9B%B8%E6%A9%9F. &lt;a href=&quot;#fnref:5&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:6&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://github.com/whuwuteng/EuroSDR_UAV_Micmac. &lt;a href=&quot;#fnref:6&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:9&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://www.wxpython.org/. &lt;a href=&quot;#fnref:9&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:10&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://github.com/Kitware/keypointgui. &lt;a href=&quot;#fnref:10&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:11&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://github.com/whuwuteng/keypointgui. &lt;a href=&quot;#fnref:11&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:8&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://github.com/whuwuteng/Stereo_Show. &lt;a href=&quot;#fnref:8&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:7&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://erupnik.github.io/blog/jupyter/2021/05/04/_05_03_satellite_basic_hide.html. &lt;a href=&quot;#fnref:7&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name></name></author><category term="markdown" /><summary type="html">Micmac tools in photogrammetry Micmac 1 是一个摄影测量的开源工具，是基于C++的，可以在Windows和Linux/MacOS X 上运行，由于开发的人主要是Ubuntu，建议在Ubuntu下用。 https://github.com/micmacIGN/micmac. &amp;#8617;</summary></entry><entry><title type="html">Parallel in Deep learning</title><link href="https://whuwuteng.github.io/personal_page/markdown/2022/06/25/parallel.html" rel="alternate" type="text/html" title="Parallel in Deep learning" /><published>2022-06-25T00:00:00-05:00</published><updated>2022-06-25T00:00:00-05:00</updated><id>https://whuwuteng.github.io/personal_page/markdown/2022/06/25/parallel</id><content type="html" xml:base="https://whuwuteng.github.io/personal_page/markdown/2022/06/25/parallel.html">&lt;h1 id=&quot;parallel-in-deep-learning&quot;&gt;Parallel in Deep learning&lt;/h1&gt;
&lt;p&gt;在cluster上用多个GPU进行训练，减少训练的时间；另外随着batch Size 增加，需要的内存也越来越大，在一块GPU上不能进行训练，因此如何用多个GPU进行训练也是一个需求。&lt;/p&gt;

&lt;h2 id=&quot;dataparallel-in-pytorch&quot;&gt;DataParallel in Pytorch&lt;/h2&gt;
&lt;p&gt;虽然DataParallel不被推荐使用，即使是在一个node中&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;，但是因为&lt;a href=&quot;https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DistributedDataParallel&lt;/code&gt;&lt;/a&gt;有一些问题，如windows不支持，所以DataParallel还是可以用的&lt;sup id=&quot;fnref:2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;。&lt;/p&gt;

&lt;p&gt;不推荐的主要原因是由于模型要在多个node中复制。&lt;/p&gt;

&lt;p&gt;另外的还有&lt;strong&gt;mp.spawn&lt;/strong&gt;来做并行，感觉需要的代码更多&lt;sup id=&quot;fnref:3&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;。&lt;/p&gt;

&lt;h2 id=&quot;distributeddataparallel-in-pytorch&quot;&gt;DistributedDataParallel in Pytorch&lt;/h2&gt;

&lt;p&gt;DistributedDataParallel 是只用Pytorch的基础上利用较多的，目前很多这样的博客，缺点就是配置起来比较困难&lt;sup id=&quot;fnref:7&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:7&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;，具体的可以参考blog&lt;sup id=&quot;fnref:8&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:8&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt;。&lt;/p&gt;

&lt;h2 id=&quot;pytorch-lightning&quot;&gt;Pytorch Lightning&lt;/h2&gt;

&lt;p&gt;是独立于Pytorch的一个库&lt;sup id=&quot;fnref:6&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:6&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;6&lt;/a&gt;&lt;/sup&gt;，因此对于分布配置时并不用考虑，可以直接从pytorch的模型到pytorch lightning&lt;sup id=&quot;fnref:5&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:5&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;7&lt;/a&gt;&lt;/sup&gt;。&lt;/p&gt;

&lt;h2 id=&quot;horovod&quot;&gt;Horovod&lt;/h2&gt;
&lt;p&gt;Horovod&lt;sup id=&quot;fnref:9&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:9&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;8&lt;/a&gt;&lt;/sup&gt; 可以认为是一个分布式训练的框架，可以支持多种工具，如TensorFlow, Keras, PyTorch, and Apache MXNet。
目前在Pytorch Lightning中，也可以支持Horovod&lt;sup id=&quot;fnref:11&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:11&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;9&lt;/a&gt;&lt;/sup&gt;，对于pytorch，也可以自己配置&lt;sup id=&quot;fnref:10&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:10&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;10&lt;/a&gt;&lt;/sup&gt;。&lt;/p&gt;

&lt;h2 id=&quot;batch-size&quot;&gt;Batch size&lt;/h2&gt;

&lt;p&gt;Batch size 是一个重要的问题，因为batch size的大小影响训练的精度，实际上的batch size是多少跟采用哪种并行方式有关，可以参考视频中的计算方式&lt;sup id=&quot;fnref:2:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;。&lt;/p&gt;

&lt;p&gt;考虑到Batch size 的变化，learning rate也需要跟着变化，要不然用DDP的accuracy会降低&lt;sup id=&quot;fnref:4&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;11&lt;/a&gt;&lt;/sup&gt;。&lt;/p&gt;

&lt;h2 id=&quot;footnotes&quot;&gt;Footnotes&lt;/h2&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://pytorch.org/docs/stable/generated/torch.nn.DataParallel.html. &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://www.youtube.com/watch?v=a6_pY9WwqdQ. &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt; &lt;a href=&quot;#fnref:2:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://zhuanlan.zhihu.com/p/336863012. &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:7&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://zhuanlan.zhihu.com/p/206467852. &lt;a href=&quot;#fnref:7&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:8&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://shomy.top/2022/01/05/torch-ddp-intro/. &lt;a href=&quot;#fnref:8&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:6&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://zhuanlan.zhihu.com/p/319810661. &lt;a href=&quot;#fnref:6&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:5&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://www.youtube.com/watch?v=DbESHcCoWbM&amp;amp;t=1678s. &lt;a href=&quot;#fnref:5&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:9&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://github.com/horovod/horovod. &lt;a href=&quot;#fnref:9&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:11&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://horovod.readthedocs.io/en/stable/pytorch.html. &lt;a href=&quot;#fnref:11&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:10&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://zhuanlan.zhihu.com/p/264778072. &lt;a href=&quot;#fnref:10&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:4&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://discuss.pytorch.org/t/should-we-split-batch-size-according-to-ngpu-per-node-when-distributeddataparallel/72769/6. &lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name></name></author><category term="markdown" /><summary type="html">Parallel in Deep learning 在cluster上用多个GPU进行训练，减少训练的时间；另外随着batch Size 增加，需要的内存也越来越大，在一块GPU上不能进行训练，因此如何用多个GPU进行训练也是一个需求。</summary></entry><entry><title type="html">Hyperparameters in Deep learning</title><link href="https://whuwuteng.github.io/personal_page/markdown/2022/03/24/hyperparameters.html" rel="alternate" type="text/html" title="Hyperparameters in Deep learning" /><published>2022-03-24T00:00:00-05:00</published><updated>2022-03-24T00:00:00-05:00</updated><id>https://whuwuteng.github.io/personal_page/markdown/2022/03/24/hyperparameters</id><content type="html" xml:base="https://whuwuteng.github.io/personal_page/markdown/2022/03/24/hyperparameters.html">&lt;h1 id=&quot;hyperparameters-in-deep-learning&quot;&gt;Hyperparameters in Deep learning&lt;/h1&gt;
&lt;p&gt;深度学习中的hyperparameters(超参数)很多，有时候对结果的影响还挺大的，根据数据的不同、模型的不同会有比较大的区别，下面只是记录一些关于这的blog的内容。&lt;/p&gt;

&lt;h2 id=&quot;batch-size&quot;&gt;Batch Size&lt;/h2&gt;
&lt;p&gt;Batch Size 是很关键的一个参数，因为它影响利用的内存、每epoch的时间等 &lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;，相同的epoch，steps（iteration）的次数也不同。在比较大的Batch Size时，learning rate同时增加，学习结果最好。&lt;/p&gt;

&lt;h2 id=&quot;upsampling&quot;&gt;Upsampling&lt;/h2&gt;

&lt;h2 id=&quot;footnotes&quot;&gt;Footnotes&lt;/h2&gt;
&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://medium.com/mini-distill/effect-of-batch-size-on-training-dynamics-21c14f7a716e . &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name></name></author><category term="markdown" /><summary type="html">Hyperparameters in Deep learning 深度学习中的hyperparameters(超参数)很多，有时候对结果的影响还挺大的，根据数据的不同、模型的不同会有比较大的区别，下面只是记录一些关于这的blog的内容。</summary></entry></feed>